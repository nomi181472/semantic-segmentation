{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7dee3a-a895-4b5b-b746-79997dc201d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchmetrics import JaccardIndex\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# Dataset with transform maps\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.mask_map = {f.replace('_mask.png', ''): f for f in os.listdir(mask_dir) if f.endswith('_mask.png')}\n",
    "        \n",
    "        all_files = sorted(os.listdir(image_dir))\n",
    "        for img in all_files:\n",
    "            if not img.endswith('.jpg'):\n",
    "                print(f\"Skipping {img} - not a .jpg file\")\n",
    "                continue\n",
    "            img_path = os.path.join(self.image_dir, img)\n",
    "            if not os.path.isfile(img_path):\n",
    "                print(f\"Skipping {img} - not a file\")\n",
    "                continue\n",
    "                \n",
    "            base_name = img.split('.rf')[0] if '.rf' in img else img.split('.')[0]\n",
    "            for mask_base in self.mask_map.keys():\n",
    "                if base_name in mask_base:\n",
    "                    self.images.append(img)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Skipping {img} - no matching mask found\")\n",
    "        \n",
    "        print(f\"Dataset size: {len(self.images)} images with masks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        base_name = img_name.split('.rf')[0] if '.rf' in img_name else img_name.split('.')[0]\n",
    "        mask_name = next((m for m in self.mask_map.values() if base_name in m), None)\n",
    "        if not mask_name:\n",
    "            raise FileNotFoundError(f\"No mask for {img_name}\")\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        # Load image and mask\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        # Apply transforms (both to image and mask)\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# Custom transform that applies the same transform to both image and mask\n",
    "class SegmentationTransform:\n",
    "    def __init__(self, img_size=256, augment=False):\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __call__(self, img, mask):\n",
    "        # Resize\n",
    "        img = TF.resize(img, (self.img_size, self.img_size))\n",
    "        mask = TF.resize(mask, (self.img_size, self.img_size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        \n",
    "        if self.augment:\n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                img = TF.hflip(img)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                img = TF.vflip(img)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "            # Random rotation\n",
    "            if random.random() > 0.5:\n",
    "                angle = random.choice([90, 180, 270])\n",
    "                img = TF.rotate(img, angle)\n",
    "                mask = TF.rotate(mask, angle)\n",
    "                \n",
    "            # Random brightness and contrast (image only)\n",
    "            if random.random() > 0.5:\n",
    "                img = TF.adjust_brightness(img, brightness_factor=random.uniform(0.8, 1.2))\n",
    "                img = TF.adjust_contrast(img, contrast_factor=random.uniform(0.8, 1.2))\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img = TF.to_tensor(img)\n",
    "        mask = torch.tensor(np.array(mask), dtype=torch.long)\n",
    "        \n",
    "        # Normalize image\n",
    "        img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "\n",
    "# PyTorch Lightning DataModule\n",
    "class SegmentationDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, image_dir, mask_dir, batch_size=4, img_size=256, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_transform = SegmentationTransform(img_size=img_size, augment=True)\n",
    "        self.val_transform = SegmentationTransform(img_size=img_size, augment=False)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Create dataset\n",
    "        full_dataset = SegmentationDataset(\n",
    "            image_dir=self.image_dir,\n",
    "            mask_dir=self.mask_dir,\n",
    "            transform=self.train_transform\n",
    "        )\n",
    "        \n",
    "        # Split dataset\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        \n",
    "        # Override dataset transforms after splitting\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "        \n",
    "        # Create separate datasets with appropriate transforms\n",
    "        train_full = SegmentationDataset(\n",
    "            image_dir=self.image_dir,\n",
    "            mask_dir=self.mask_dir,\n",
    "            transform=self.train_transform\n",
    "        )\n",
    "        \n",
    "        val_full = SegmentationDataset(\n",
    "            image_dir=self.image_dir,\n",
    "            mask_dir=self.mask_dir,\n",
    "            transform=self.val_transform\n",
    "        )\n",
    "        \n",
    "        # Use the same indices from the random split\n",
    "        self.train_dataset = torch.utils.data.Subset(train_full, self.train_dataset.indices)\n",
    "        self.val_dataset = torch.utils.data.Subset(val_full, self.val_dataset.indices)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "\n",
    "# Lightning Module\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, encoder_name=\"resnet34\", num_classes=2, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=\"imagenet\",\n",
    "            in_channels=3,\n",
    "            classes=num_classes\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.iou_metric = JaccardIndex(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        \n",
    "        # Calculate IoU\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        iou = self.iou_metric(preds, masks)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_iou', iou, prog_bar=True)\n",
    "        \n",
    "        # Log images to TensorBoard periodically\n",
    "        if batch_idx % 50 == 0:\n",
    "            self._log_images(images, masks, preds, \"train\")\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        \n",
    "        # Calculate IoU\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        iou = self.iou_metric(preds, masks)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_iou', iou, prog_bar=True)\n",
    "        \n",
    "        # Log images to TensorBoard\n",
    "        if batch_idx == 0:\n",
    "            self._log_images(images, masks, preds, \"val\")\n",
    "            \n",
    "        return {\"val_loss\": loss, \"val_iou\": iou}\n",
    "    \n",
    "    def _log_images(self, images, masks, preds, stage):\n",
    "        # Log a subset of images to TensorBoard\n",
    "        img_idx = np.random.choice(images.size(0))\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        img = images[img_idx].cpu().numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        mask = masks[img_idx].cpu().numpy()\n",
    "        pred = preds[img_idx].cpu().numpy()\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title(\"Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        axes[1].imshow(mask, cmap=\"viridis\")\n",
    "        axes[1].set_title(\"Ground Truth\")\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "        axes[2].imshow(pred, cmap=\"viridis\")\n",
    "        axes[2].set_title(\"Prediction\")\n",
    "        axes[2].axis(\"off\")\n",
    "        \n",
    "        # Log figure to TensorBoard\n",
    "        self.logger.experiment.add_figure(f\"{stage}_predictions\", fig, self.global_step)\n",
    "        plt.close(fig)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# Main training script\n",
    "def main():\n",
    "    # Data module\n",
    "    data_module = SegmentationDataModule(\n",
    "        image_dir=\"dataset/images/\",\n",
    "        mask_dir=\"dataset/masks/\",\n",
    "        batch_size=8,\n",
    "        img_size=256,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = SegmentationModel(\n",
    "        encoder_name=\"resnet34\", \n",
    "        num_classes=2,\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        filename=\"model-{epoch:02d}-{val_loss:.4f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "    \n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    \n",
    "    # Logger\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=\"segmentation\")\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",  # Uses GPU if available, otherwise CPU\n",
    "        devices=1,\n",
    "        max_epochs=20,\n",
    "        callbacks=[checkpoint_callback, lr_monitor],\n",
    "        logger=logger,\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.fit(model, data_module)\n",
    "    \n",
    "    # Save final model\n",
    "    trainer.save_checkpoint(\"final_segmentation_model.ckpt\")\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d90fc79-9cb3-4e01-94a8-88c63f02706e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f8866-884b-48bb-8fef-9b2e8fb9807b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34568c7b-49f8-4fa7-ad05-214eb87b1668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
